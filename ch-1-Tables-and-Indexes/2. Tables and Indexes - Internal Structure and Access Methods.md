- [Tables and Indexes - Internal Structure and Access Methods](#tables-and-indexes---internal-structure-and-access-methods)
  - [Heap Tables](#heap-tables)
  - [Clustered Indexes](#clustered-indexes)
    - [Ordered scan](#ordered-scan)
    - [Allocation order scan](#allocation-order-scan)
    - [Index seek](#index-seek)
    - [SARGable](#sargable)
  - [Composit Indexes](#composit-indexes)
  - [Nonclustered Indexes](#nonclustered-indexes)
  - [Summary](#summary)

<br>

# Tables and Indexes - Internal Structure and Access Methods

## Heap Tables
Heap tables are tables without a clustered index. The data in heap tables is unsorted. ***SQL Server does not guarantee, nor does it maintain, a sorting order of the data in heap tables.***

When inserting data into heep tables, Sql server uses the page free space (PFS) allocation map. it errs on the side of caution and uses the low value from the PFS free space percentage tier during the estimation.  
For example, if a data page stores 4,100 bytes of data, and as result it has 3,960 bytes of free space available, PFS would indicate that the page is [51–80 percent full](1.%20Data%20Storage%20Internals.md#page-free-space-pfs). SQL Server would not put a new row on the page if its size exceeds 20 percent (8,060 bytes * 0.2 = 1,612 bytes) of the page size.  
This behavior leads to the situation where SQL Server unnecessarily allocates new data pages, leaving large amounts of free space unused. It is not always a problem when the size of rows vary—in those cases, SQL Server eventually fills empty spaces with the smaller rows. However, especially in cases when all rows are relatively large, you can end up with large amounts of unused space on the data pages.

When selecting data from the heap table, SQL Server uses an index allocation map (IAM) to find the pages and extents that need to be scanned. It analyzes what extents belong to the table and processes them based on their allocation order rather than on the order in which the data was inserted.

When you update a row in the heap table, SQL Server tries to accommodate it on the same page. If there is no free space available, SQL Server moves the new version of the row to another page and replaces the old row with a special 16-byte row called a ***forwarding pointer***. The new version of the row is called ***forwarded row.***

There are two main reasons why forwarding pointers are used.  
1. They prevent updates of nonclustered index keys that reference the row.
2. They help minimize the number of duplicated reads.  
   e.g. Let’s further assume that the row in page 3 was modified after the page was read at the time when SQL Server was reading page 4. The new version of the row would be moved to page 5, which has yet to be processed. Without forwarding pointers, SQL Server would not know that the old version of the row had already been read, and it would read it again during the page 5 scan. With forwarding pointers, SQL Server would ignore the forwarded rows—they have a bit set in the Status Bits A byte in the data row.

Although forwarding pointers help minimize duplicated reads, they introduce additional read operations at the same time. SQL Server follows the forwarding pointers and reads the new versions of the rows at the time it encounters them. That behavior can introduce an excessive number of I/O operations.
![Reading data when forwarding pointers exist](assets/Reading%20data%20when%20forwarding%20pointers%20exist.jpg)
When SQL Server reads the forwarding pointer rows from page 1, it follows them and reads pages 2 and 3 immediately. After that, SQL Server reads those pages one more time during the regular IAM scan process. As a result, we have five read operations, even though our table has just three data pages.

As you can see, the large number of forwarding pointers leads to extra I/O operations and significantly reduces the performance of the queries accessing the data.

When the size of the forwarded row is reduced by another update and the data page with forwarding pointer has enough space to accommodate the updated version of the row, SQL Server may move it back to its original data page and remove the forwarding pointer row. Nevertheless, the only reliable way to get rid of all of the forwarding pointers is by rebuilding the heap table.

**Heap tables can be useful in staging environments,** where you want to import a large amount of data into the system as fast as possible. Inserting data into heap tables can often be faster than inserting it into tables with clustered indexes. Nevertheless, during a regular workload, tables with clustered indexes usually outperform heap tables, which have suboptimal space control and extra I/O operations introduced by forwarding pointers.

## Clustered Indexes

A clustered index dictates the physical order of the data in a table, which is sorted according to the clustered index key. The table can have only one clustered index defined.
![Clustered index structure](assets/Clustered%20index%20structure.jpg)

> **Note**  
> The sort order on the page is controlled by a slot array. Actual data on the page is unsorted.

The number of levels in the index largely depends on the row and index key sizes. For example, the index on the 4-byte integer column will require 13 bytes per row on the intermediate and root levels. Those 13 bytes consist of a 2-byte slot-array entry, a 4-byte index-key value, a 6-byte page pointer, and a 1-byte row overhead, which is adequate because the index key does not contain variable-length and NULL columns. 

As a result, you can accommodate 8,060 bytes / 13 bytes per row = 620 rows per page. This means that, with the one intermediate level, you can store information about up to 620 * 620 = 384,400 leaf-level pages. If your data row size is 200 bytes, you can store 40 rows per leaf-level page and up to 15,376,000 rows in the index with just three levels. Adding another intermediate level to the index would essentially cover all possible integer values.

There are three different ways in which SQL Server can read data from the index.

### Ordered scan
We want to run the SELECT Name FROM dbo.Customers ORDER BY CustomerId query. The data on the leaf level of the index is already sorted based on the CustomerId column value. As a result, SQL Server can scan the leaf level of the index from the first to the last page and return the rows in the order in which they were stored.

SQL Server starts with the root page of the index and reads the first row from there. That row references the intermediate page with the minimum key value from the table. SQL Server reads that page and repeats the process until it finds the first page on the leaf level. Then, SQL Server starts to read rows one by one, moving through the linked list of the pages until all rows have been read.
![Ordered scan process](assets/Ordered%20scan%20process.jpg)

The execution plan for the preceding query shows the Clustered Index Scan operator with the ***Ordered property*** set to true,

It is worth mentioning that the order by clause is not required for an ordered scan to be triggered. An ordered scan just means that SQL Server reads the data based on the order of the index key.

SQL Server can navigate through indexes in both directions, forward and backward. However, there is one important aspect that you must keep in mind: ***SQL Server does not use parallelism during backward index scans.***

You cannot rely on the order of the index keys. ***You should always specify an ORDER BY clause when it matters.***

### Allocation order scan
SQL Server accesses the table data through the IAM pages, similar to how it does so with heap tables.
![Allocation order scan](assets/Allocation%20order%20scan.jpg)

An allocation order scan can be faster for scanning large tables, although it has a higher startup cost. SQL Server does not use this access method when the table is small. Another important consideration is data consistency. SQL Server does not use forwarding pointers in tables that have a clustered index, and an allocation order scan can produce inconsistent results. Rows can be skipped or read multiple times due to the data movement caused by page splits. As a result, SQL Server usually avoids using allocation order scans unless it reads the data in READ UNCOMMITTED or SERIALIZABLE transaction-isolation levels.

### Index seek
SELECT Name FROM dbo.Customers WHERE CustomerId BETWEEN 4 AND 7
![Index seek process](assets/Index%20seek%20process.jpg)

SQL Server starts with the root page, where the second row references the page with the minimum key value of 350. It is greater than the key value that we are looking for (4), and SQL Server reads the intermediate-level data page (1:170) referenced by the first row on the root page.   
Similarly, the intermediate page leads SQL Server to the first leaf-level page (1:176). SQL Server reads that page, then it reads the rows with CustomerIds equal to 4 and 5, and, finally, it reads the two remaining rows from the second page.

Index seek is more efficient than index scan, because SQL Server processes just the subset of rows and data pages rather than scanning the entire table.

### SARGable
There is a concept in relational databases called SARGable predicates, which stands for Search Argument able. The predicate is SARGable if SQL Server can utilize an index seek operation, if an index exists. In a nutshell, predicates are SARGable when SQL Server can isolate the single value or range of index key values to process, thus limiting the search during predicate evaluation. Obviously, it is beneficial to write queries using SARGable predicates and utilize index seek whenever possible.

SARGable predicates include the following operators: =, >, >=, <, <=, IN, BETWEEN, and LIKE (in case of prefix matching). Non-SARGable operators include NOT, <>, LIKE (in case of non-prefix matching), and NOT IN.

Another circumstance for making predicates non-SARGable is using functions or mathematical calculations against the table columns. SQL Server has to call the function or perform the calculation for every row it processes.

|Operation|Non-SARGable implementation|SARGable implementation|
|---|---|---|
|Mathematical calculations|Column - 1 = @Value|Column = @Value + 1|
|---|ABS(Column) = 1|Column IN (-1, 1)|
|Date manipulation|CAST(Column as date) = @Date (in SQL Server prior 2008) convert(datetime, convert(varchar(10),Column,121))|Column >= @Date and Column < DATEADD(day,1,@Date)|
||DATEPART(year,Column) = @Year|Column >= @Year and Column < DATEADD(year,1,@Year)|
||DATEADD(day,7,Column) > GETDATE()|Column > DATEADD(day,-7,GETDATE())|
|Prefix search|LEFT(Column,3) = 'ABC'|Column LIKE 'ABC%'|
|Substring search|Column LIKE '%ABC%'|Use Full-Text Search or other technologies|

Another important factor that you must keep in mind is type conversion. In some cases, you can make predicates non-SARGable by using incorrect data types.
![non-SARGAble data conversion](assets/non-SARGAble%20data%20conversion.jpg)
> **Tip**  
> Pay attention to the column data types in the join predicates. Implicit or explicit data type conversions can significantly decrease the performance of the queries.

You will observe very similar behavior in the case of unicode string parameters.  
e.g.
```
select * from dbo.Data where VarcharKey = '200';  
select * from dbo.Data where VarcharKey = N'200'; -- unicode parameter
```
A unicode string parameter is non-SARGable for varchar columns.  
Always specify parameter data types in client applications.

It is also worth mentioning that varchar parameters are SARGable for nvarchar unicode data columns.

## Composit Indexes
Indexes with multiple key columns are called composite (or compound) indexes. The data in the composite indexes is sorted on a per-column basis from leftmost to rightmost columns.
![composit index structure](assets/composit%20index%20structure.jpg)

The SARGability of a composite index depends on the SARGability of the predicates on the leftmost index columns.
|SARGable predicates|Non-SARGable predicates|
|---|---|
|LastName = 'Clark' and FirstName = 'Steve'|FirstName|
|LastName = 'Clark' and FirstName <> 'Steve'|LastName LIKE '%ar%' and FirstName = 'Steve'|
|LastName = 'Clark'|FirstName = 'Steve'|
|LastName LIKE 'Cl%'||

## Nonclustered Indexes
While a clustered index specifies how data rows are sorted in a table, nonclustered indexes define a separate sorting order for a column or set of columns and persist them as a separate data structure.

![Clustered and nonclustered index structures](assets/Clustered%20and%20nonclustered%20index%20structures%20.png)
*Clustered and nonclustered index structures*

The leaf level of the nonclustered index is sorted based on the value of the index key—Name in our case. Every row on the leaf level includes the key value and row-id. For heap tables, row-id is the physical location of the row, defined as file:page:slot, and has the size of eight bytes.

> **Note**  
> Another reason why SQL Server uses forwarding pointers in heap tables is to prevent the updating of nonclustered index rows when the original row in the heap table has been moved to another data page after the update. Nonclustered indexes keep the old row-id, which references the forwarding pointer row.

For tables with a clustered index, row-id represents the value of the clustered index key of the row.

> **Note**
> Nonclustered indexes do not store information about physical row location when a table has a clustered index. They store the value of the clustered index key instead.

Like clustered indexes, the intermediate and root levels of nonclustered indexes store one row per page from the level they reference. That row consists of the physical address and the minimum value of the key from the page. **In addition, for non-unique indexes**, it also stores the row-id of such a row.

> **Note**
> It is important to define a nonclustered index as unique when the data is unique. Intermediate- and root-level rows of unique indexes are more compact, because SQL Server does not maintain the row-id there. Moreover, the uniqueness of the index helps Query Optimizer generate more efficient execution plans.

*SELECT * FROM dbo.Customers WHERE Name = 'Boris'*
![Nonclustered index usage step 1](assets/Nonclustered%20index%20usage%20step1.png)
![Nonclustered index usage step 2](assets/Nonclustered%20index%20usage%20step2.png)


1. SQL Server starts with the root page of the nonclustered index. The key value Boris is less than Dan, and SQL Server goes to the intermediate page referenced from the first row in the root-level page.
2. The second row of the intermediate page indicates that the minimum key value on the page is Boris, although the index had not been defined as unique and SQL Server does not know if there are other Boris rows stored on the first page. As a result, it goes to the first leaf page of the index and finds the row with the key value Boris and a row-id equal to 7 there.  
In our case, the nonclustered index does not have any data besides CustomerId and Name, and SQL Server needs to traverse the clustered index tree and obtain the data from other columns from there. This operation is called **key lookup**.
3. SQL Server comes back to the nonclustered index and reads the second page from the leaf level. It finds another row with the key value Boris and row-id 93712, and it performs a key lookup again.

> **Key Lookups vs. RID Lookups**  
> Nonclustered indexes defined on heap tables reference the actual location of the rows in the data file. SQL Server uses the RID lookup operation to obtain the data row from the heap. In theory, RID lookup seems to be more efficient than key lookup, because it can read the row directly without traversing the root and intermediate levels of the clustered index.  
> In reality, however, the performance impact of reading non-leaf clustered index data pages is relatively small. Those pages are usually cached in the buffer pool and do not introduce physical I/O to access. Logical reads still introduce some overhead; however, it is usually insignificant compared to physical I/O and disk access. Moreover, forwarding pointers in the heap tables can introduce multiple physical reads during a single RID lookup operation, which would impact its performance.

There is another important factor contributing to nonclustered index inefficiency. Key lookups read the data from different places in the data files. Even though data pages from root and intermediate index levels are often cached and introduce just logical reads, accessing leaf-level pages leads to random physical I/O activity.  
As a result, SQL Server is very conservative in choosing nonclustered indexes **when it expects that a large number of key or RID lookup operations will be required.**

> **Important**
> SQL Server does not use nonclustered indexes if it estimates that a large number of key or RID lookup operations will be required.

Nonclustered indexes help improve the performance of queries, although this comes at its own price. They maintain a copy of the data from the index columns. When columns are updated, **SQL Server needs to update them in the every index in which they are included.**

## Summary
Clustered indexes define the sorting order for data in a table. Nonclustered indexes store a copy of the data for a subset of table columns sorted in the order in which the key columns are defined.

Both clustered and nonclustered indexes are stored in a multiple-level tree-like structure called a B-Tree. Data pages on each level are linked in a double-linked list.

The leaf level of the clustered index stores the actual table data. The intermediate- and root-level pages store one row per page from the next level. Every row includes the physical address and minimum value of the key from the page that it references.

The leaf level of a nonclustered index stores the data from the index columns and row-id. For tables with a clustered index, row-id is the clustered key value of the row. Then intermediate and root levels of a nonclustered index are similar to those of a clustered index, although when the index is not unique, those rows store row-id in addition to the minimum index key value. ***It is beneficial to define indexes as unique***, as it makes the intermediate and root levels more compact. Moreover, uniqueness helps Query Optimizer generate more efficient execution plans.

SQL Server needs to traverse the clustered index tree to obtain any data from the columns that are not part of the nonclustered index. Those operations, called key lookups, are expensive in terms of I/O. ***SQL Server does not use nonclustered indexes if it expects that a large number of key or RID lookup operations will be required.***

Tables with a clustered index usually outperform heap tables. It is thus beneficial to define a clustered index on tables in most cases.

SQL Server can utilize indexes in two separate ways. The first way is an index scan operation, where it reads every page from the index. The second one is an index seek operation, where SQL Server processes just a subset of the index pages. It is beneficial to use SARGable predicates in queries, which allows SQL Server to perform index seek operations by exactly matching the row or range of rows in the index.

You should avoid calculations and/or function calls against data columns, because it makes predicates non-SARGable. You should also take care to use the correct data types for parameters, especially when dealing with unicode and non-unicode strings.